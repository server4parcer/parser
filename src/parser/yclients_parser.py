"""
YCLIENTS Parser - –û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã YCLIENTS.
"""
import asyncio
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple

from playwright.async_api import async_playwright, Browser, BrowserContext, Page, TimeoutError
import re

from src.browser.browser_manager import BrowserManager
from src.browser.proxy_manager import ProxyManager
from src.database.db_manager import DatabaseManager
from src.parser.production_data_extractor import ProductionDataExtractor
from src.parser.yclients_real_selectors import YCLIENTS_REAL_SELECTORS
from config.settings import PARSE_INTERVAL, MAX_RETRIES, TIMEOUT, USER_AGENTS, PAGE_LOAD_TIMEOUT


logger = logging.getLogger(__name__)


class YClientsParser:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö —Å YCLIENTS.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Playwright –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ –∏ —ç–º—É–ª—è—Ü–∏–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    """

    def __init__(self, urls: List[str], db_manager: DatabaseManager):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞.
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL-–∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
            db_manager: –≠–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        """
        self.urls = urls
        self.db_manager = db_manager
        self.browser_manager = BrowserManager()
        self.proxy_manager = ProxyManager()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º production-ready —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        self.data_extractor = ProductionDataExtractor()
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.current_proxy = None
        self.retry_count = 0
        self.last_parsed_urls = {}  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL

    async def initialize(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
        try:
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
            self.current_proxy = self.proxy_manager.get_next_proxy()
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±—Ä–∞—É–∑–µ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Å—Ç–µ–ª—Å-—Ä–µ–∂–∏–º–∞
            self.browser, self.context = await self.browser_manager.initialize_browser(
                proxy=self.current_proxy
            )
            
            logger.info("–ë—Ä–∞—É–∑–µ—Ä —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞: {str(e)}")
            raise

    async def close(self) -> None:
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞ –∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        try:
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
            logger.info("–ë—Ä–∞—É–∑–µ—Ä –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–∫—Ä—ã—Ç—ã")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞: {str(e)}")

    async def navigate_to_url(self, url: str) -> bool:
        """
        –ü–µ—Ä–µ—Ö–æ–¥ –ø–æ URL —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.
        
        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            
        Returns:
            bool: True –µ—Å–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥ —É—Å–ø–µ—à–µ–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ —Ç–µ–∫—É—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            self.page = await self.context.new_page()
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —é–∑–µ—Ä-–∞–≥–µ–Ω—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
            user_agent = self.browser_manager.get_random_user_agent()
            await self.page.set_extra_http_headers({"User-Agent": user_agent})
            
            # –≠–º—É–ª—è—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: —Å–ª—É—á–∞–π–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –ø–µ—Ä–µ–¥ –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π
            await asyncio.sleep(self.browser_manager.get_random_delay(1, 3))
            
            logger.info(f"–ü–µ—Ä–µ—Ö–æ–¥ –ø–æ URL: {url}")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            response = await self.page.goto(
                url, 
                timeout=PAGE_LOAD_TIMEOUT,
                wait_until="networkidle"
            )
            
            if not response or response.status >= 400:
                logger.error(f"–ù–µ—É–¥–∞—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ {url}, —Å—Ç–∞—Ç—É—Å: {response.status if response else 'unknown'}")
                return False
            
            # –ñ–¥–µ–º –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            await self.page.wait_for_load_state("networkidle")
            
            # –≠–º—É–ª—è—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–∫—Ä–æ–ª–ª–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            await self.browser_manager.emulate_human_scrolling(self.page)
            
            return True
            
        except TimeoutError:
            logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
            return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –Ω–∞ {url}: {str(e)}")
            return False

    async def handle_service_selection_page(self, url: str) -> List[str]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä—è–º—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ.
        –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞ —Å URL —Ç–∏–ø–∞ record-type?o=
        
        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ –ø—Ä—è–º—ã—Ö URL –¥–ª—è –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —É—Å–ª—É–≥
        """
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥: {url}")
        direct_urls = []
        
        try:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥
            navigation_success = await self.navigate_to_url(url)
            if not navigation_success:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥: {url}")
                return []
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ —É—Å–ª—É–≥
            try:
                await self.page.wait_for_selector('.service-item, .service-option, .record__service', timeout=10000)
            except Exception:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ —É—Å–ª—É–≥")
                return []
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —É—Å–ª—É–≥–∏
            service_selectors = [
                '.service-item', '.service-option', '.record__service',
                '.ycwidget-service', '.booking-service-item'
            ]
            
            service_elements = []
            for selector in service_selectors:
                elements = await self.page.query_selector_all(selector)
                if elements:
                    service_elements = elements
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(elements)} —É—Å–ª—É–≥ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                    break
            
            if not service_elements:
                logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã —É—Å–ª—É–≥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                return []
            
            # –î–ª—è –∫–∞–∂–¥–æ–π —É—Å–ª—É–≥–∏ –ø–æ–ª—É—á–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É
            for i, service_element in enumerate(service_elements[:5]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                try:
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Å—ã–ª–∫—É –≤–Ω—É—Ç—Ä–∏ —ç–ª–µ–º–µ–Ω—Ç–∞
                    link_element = await service_element.query_selector('a')
                    if link_element:
                        href = await link_element.get_attribute('href')
                        if href:
                            if href.startswith('/'):
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –≤ –∞–±—Å–æ–ª—é—Ç–Ω—É—é
                                base_url = '/'.join(url.split('/')[:3])
                                direct_url = base_url + href
                            else:
                                direct_url = href
                            
                            if 'record' in direct_url and direct_url not in direct_urls:
                                direct_urls.append(direct_url)
                                logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞: {direct_url}")
                                continue
                    
                    # –ï—Å–ª–∏ —Å—Å—ã–ª–∫–∏ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç
                    logger.info(f"–ö–ª–∏–∫–∞–µ–º –Ω–∞ —É—Å–ª—É–≥—É {i+1}")
                    await service_element.click()
                    await asyncio.sleep(2)  # –ñ–¥–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
                    
                    # –ü–æ–ª—É—á–∞–µ–º URL –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞
                    current_url = self.page.url
                    if 'record' in current_url and current_url != url and current_url not in direct_urls:
                        direct_urls.append(current_url)
                        logger.info(f"–ü–æ–ª—É—á–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞: {current_url}")
                    
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥
                    await self.page.go_back()
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —É—Å–ª—É–≥–∏ {i+1}: {str(e)}")
                    continue
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(direct_urls)} –ø—Ä—è–º—ã—Ö —Å—Å—ã–ª–æ–∫ –¥–ª—è –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
            return direct_urls
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥: {str(e)}")
            return []

    async def check_for_antibot(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∞–Ω—Ç–∏–±–æ—Ç-–∑–∞—â–∏—Ç—ã –∏ –µ—ë –æ–±—Ö–æ–¥, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ.
        
        Returns:
            bool: True –µ—Å–ª–∏ –∑–∞—â–∏—Ç—ã –Ω–µ—Ç –∏–ª–∏ –æ–Ω–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–æ–π–¥–µ–Ω–∞, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–∞–ø—á–∏ –∏–ª–∏ –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º –∑–∞—â–∏—Ç—ã
            captcha_exists = await self.page.query_selector(".captcha, .recaptcha, .hcaptcha")
            if captcha_exists:
                logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CAPTCHA, –ø–æ–ø—ã—Ç–∫–∞ –æ–±—Ö–æ–¥–∞...")
                # –ó–¥–µ—Å—å –º–æ–≥–ª–∞ –±—ã –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ö–æ–¥–∞ –∫–∞–ø—á–∏
                # –í –¥–∞–Ω–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –º–µ–Ω—è–µ–º –ø—Ä–æ–∫—Å–∏
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É IP
            blocked_ip = await self.page.query_selector(".blocked, .access-denied, .error-403")
            if blocked_ip:
                logger.warning("IP –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω, —Å–º–µ–Ω–∞ –ø—Ä–æ–∫—Å–∏")
                return False
                
            # –î—Ä—É–≥–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –∞–Ω—Ç–∏–±–æ—Ç-–∑–∞—â–∏—Ç—É...
            
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∞–Ω—Ç–∏–±–æ—Ç-–∑–∞—â–∏—Ç—ã: {str(e)}")
            return False

    async def navigate_yclients_flow(self, page: Page, url: str) -> List[Dict]:
        """
        Navigate through YClients 4-step booking flow.
        Step 1: Service selection (record-type)
        Step 2: Court selection (select-master)
        Step 3: Date/time selection (select-time)
        Step 4: Service packages with prices (select-services)
        """
        results = []
        
        try:
            # Step 1: Load and select service type
            await page.goto(url, wait_until='networkidle')
            await page.wait_for_selector('ui-kit-simple-cell', timeout=10000)
            
            # Click on "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏" or first available service
            service_links = await page.get_by_role('link').all()
            for link in service_links:
                text = await link.text_content()
                if '–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ' in text or '—É—Å–ª—É–≥–∏' in text.lower():
                    await link.click()
                    break
            
            # Step 2: Select courts
            await page.wait_for_url('**/personal/select-master**')
            await page.wait_for_selector('ui-kit-simple-cell')
            
            courts = await page.locator('ui-kit-simple-cell').all()
            for court in courts[:3]:  # Limit to first 3 courts for testing
                court_name = await court.locator('ui-kit-headline').text_content()
                await court.click()
                
                # Continue to date selection
                continue_btn = page.get_by_role('button', { 'name': '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å' })
                if await continue_btn.is_visible():
                    await continue_btn.click()
                
                # Step 3: Select dates and times
                await page.wait_for_url('**/personal/select-time**')
                await self.extract_time_slots_with_prices(page, court_name, results)
                
                # Go back to court selection
                await page.go_back()
                await page.wait_for_selector('ui-kit-simple-cell')
        
        except Exception as e:
            logger.error(f"Error in 4-step navigation: {str(e)}")
        
        return results

    async def extract_time_slots_with_prices(self, page: Page, court_name: str, results: List[Dict]):
        """Extract time slots and navigate to get prices."""
        
        try:
            # Get available dates
            dates = await page.locator('.calendar-day:not(.disabled)').all()
            
            for date in dates[:2]:  # Limit to 2 dates for testing
                date_text = await date.text_content()
                await date.click()
                await page.wait_for_timeout(1000)
                
                # Get time slots
                time_slots = await page.locator('[data-time]').all()
                if not time_slots:
                    # Try alternative selector
                    time_slots = await page.get_by_text(re.compile(r'\d{1,2}:\d{2}')).all()
                
                for slot in time_slots[:3]:  # Limit to 3 slots per date
                    time_text = await slot.text_content()
                    await slot.click()
                    
                    # Continue to services/prices
                    continue_btn = page.get_by_role('button', { 'name': '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å' })
                    if await continue_btn.is_visible():
                        await continue_btn.click()
                        
                        # Step 4: Extract prices from service packages
                        await page.wait_for_url('**/personal/select-services**')
                        await page.wait_for_selector('ui-kit-simple-cell')
                        
                        services = await page.locator('ui-kit-simple-cell').all()
                        for service in services:
                            try:
                                name = await service.locator('ui-kit-headline').text_content()
                                price = await service.locator('ui-kit-title').text_content()
                                duration = await service.locator('ui-kit-body').text_content()
                                
                                # Clean and structure data
                                result = {
                                    'url': page.url,
                                    'court_name': court_name.strip() if court_name else '',
                                    'date': self.parse_date(date_text),
                                    'time': time_text.strip() if time_text else '',
                                    'service_name': name.strip() if name else '',
                                    'price': self.clean_price(price),
                                    'duration': self.parse_duration(duration),
                                    'venue_name': self.extract_venue_name(page.url),
                                    'extracted_at': datetime.now().isoformat()
                                }
                                results.append(result)
                            except Exception as e:
                                logger.warning(f"Failed to extract service: {e}")
                        
                        # Go back to time selection
                        await page.go_back()
                        await page.wait_for_timeout(1000)
        except Exception as e:
            logger.error(f"Error extracting time slots with prices: {str(e)}")

    def clean_price(self, price_text: str) -> str:
        """Clean price text: '6,000 ‚ÇΩ' -> '6000 ‚ÇΩ'"""
        if not price_text:
            return "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
        # Remove spaces and commas from numbers
        cleaned = re.sub(r'(\d),(\d)', r'\1\2', price_text)
        cleaned = re.sub(r'(\d)\s+(\d)', r'\1\2', cleaned)
        cleaned = cleaned.strip()
        return cleaned if '‚ÇΩ' in cleaned or '—Ä—É–±' in cleaned else f"{cleaned} ‚ÇΩ"

    def parse_duration(self, duration_text: str) -> int:
        """Parse duration: '1 —á 30 –º–∏–Ω' -> 90"""
        if not duration_text:
            return 60
        
        total_minutes = 0
        # Extract hours
        hour_match = re.search(r'(\d+)\s*—á', duration_text)
        if hour_match:
            total_minutes += int(hour_match.group(1)) * 60
        
        # Extract minutes
        min_match = re.search(r'(\d+)\s*–º–∏–Ω', duration_text)
        if min_match:
            total_minutes += int(min_match.group(1))
        
        return total_minutes if total_minutes > 0 else 60

    def parse_date(self, date_text: str) -> str:
        """Parse date from calendar text to ISO format."""
        # For now, return current date. Can be enhanced with proper date parsing
        # Russian month mapping
        months = {
            '—è–Ω–≤–∞—Ä': '01', '—Ñ–µ–≤—Ä–∞–ª': '02', '–º–∞—Ä—Ç': '03', '–∞–ø—Ä–µ–ª': '04',
            '–º–∞–π': '05', '–º–∞–π': '05', '–∏—é–Ω': '06', '–∏—é–ª': '07',
            '–∞–≤–≥—É—Å—Ç': '08', '—Å–µ–Ω—Ç—è–±—Ä': '09', '–æ–∫—Ç—è–±—Ä': '10',
            '–Ω–æ—è–±—Ä': '11', '–¥–µ–∫–∞–±—Ä': '12'
        }
        
        try:
            # Try to extract day and month
            day_match = re.search(r'(\d{1,2})', date_text)
            if day_match:
                day = day_match.group(1).zfill(2)
                # Find month
                for month_name, month_num in months.items():
                    if month_name in date_text.lower():
                        year = datetime.now().year
                        return f"{year}-{month_num}-{day}"
        except:
            pass
        
        return datetime.now().strftime('%Y-%m-%d')

    def extract_venue_name(self, url: str) -> str:
        """Extract venue name from URL or page content."""
        # This is a placeholder - actual implementation would extract from page
        if 'n1165596' in url:
            return '–ù–∞–≥–∞—Ç–∏–Ω—Å–∫–∞—è'
        elif 'n1308467' in url:
            return '–ö–æ—Ä—Ç—ã-–°–µ—Ç–∫–∏'
        elif 'b861100' in url:
            return 'Padel Friends'
        elif 'b1009933' in url:
            return '–¢–ö –†–∞–∫–µ—Ç–ª–æ–Ω'
        elif 'b918666' in url:
            return 'Padel A33'
        return 'Unknown Venue'

    async def extract_available_dates(self) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.
        
        Returns:
            List[Dict[str, Any]]: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç
        """
        logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
        try:
            # –û–∂–∏–¥–∞–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
            await self.page.wait_for_selector(YCLIENTS_REAL_SELECTORS["calendar"]["calendar_container"], timeout=TIMEOUT)
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç
            date_elements = await self.page.query_selector_all(YCLIENTS_REAL_SELECTORS["calendar"]["available_dates"])
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            available_dates = []
            for date_element in date_elements:
                # –ü–æ–ª—É—á–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã, —Ç–µ–∫—Å—Ç –∏ –¥—Ä—É–≥–∏–µ –¥–∞–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç–∞
                date_text = await date_element.text_content()
                date_attr = await date_element.get_attribute("data-date")
                
                if date_text and date_attr:
                    available_dates.append({
                        "date": date_attr,
                        "display_text": date_text.strip()
                    })
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(available_dates)} –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç")
            return available_dates
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç: {str(e)}")
            return []

    async def extract_time_slots(self, date: str) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –¥–∞—Ç—ã.
        
        Args:
            date: –î–∞—Ç–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞
            
        Returns:
            List[Dict[str, Any]]: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤
        """
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –¥–ª—è –¥–∞—Ç—ã: {date}")
        try:
            # –í—ã–±–∏—Ä–∞–µ–º –¥–∞—Ç—É –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä–µ
            date_selector = YCLIENTS_REAL_SELECTORS["calendar"]["date_selector"].format(date=date)
            date_element = await self.page.query_selector(date_selector)
            
            if not date_element:
                logger.warning(f"–≠–ª–µ–º–µ–Ω—Ç –¥–∞—Ç—ã {date} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return []
                
            # –ö–ª–∏–∫–∞–µ–º –Ω–∞ –¥–∞—Ç—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤
            await date_element.click()
            await asyncio.sleep(2)  # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ—Ç–æ–≤
            
            # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å–æ —Å–ª–æ—Ç–∞–º–∏
            await self.page.wait_for_selector(YCLIENTS_REAL_SELECTORS["time_slots"]["container"], timeout=TIMEOUT)
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤
            slot_elements = await self.page.query_selector_all(YCLIENTS_REAL_SELECTORS["time_slots"]["slots"])
            
            time_slots = []
            for slot_element in slot_elements:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–∞—Ç–∞ –≤—ã—Ö–æ–¥–Ω—ã–º –¥–Ω–µ–º
                date_obj = datetime.strptime(date, "%Y-%m-%d")
                is_weekend = date_obj.weekday() >= 5  # 5 –∏ 6 - —Å—É–±–±–æ—Ç–∞ –∏ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ–ª–µ–π
                slot_data = await self.data_extractor.extract_slot_data_fixed(
                    slot_element
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—É, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
                if "date" not in slot_data:
                    slot_data["date"] = date
                    
                time_slots.append(slot_data)
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(time_slots)} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –¥–ª—è –¥–∞—Ç—ã {date}")
            return time_slots
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –¥–ª—è –¥–∞—Ç—ã {date}: {str(e)}")
            return []

    async def parse_url(self, url: str) -> Tuple[bool, List[Dict[str, Any]]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å –æ–¥–Ω–æ–≥–æ URL.
        –û–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥ (record-type).
        
        Args:
            url: URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
            
        Returns:
            Tuple[bool, List[Dict[str, Any]]]: –°—Ç–∞—Ç—É—Å —É—Å–ø–µ—Ö–∞ –∏ —Å–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        """
        logger.info(f"–ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ URL: {url}")
        all_data = []
        success = False
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥
            if 'record-type' in url or 'select-service' in url:
                logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤—ã–±–æ—Ä–∞ —É—Å–ª—É–≥, –ø–æ–ª—É—á–∞–µ–º –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏")
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —É—Å–ª—É–≥–∏
                direct_urls = await self.handle_service_selection_page(url)
                
                if not direct_urls:
                    logger.warning("–ù–µ –ø–æ–ª—É—á–µ–Ω—ã –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏, –ø–æ–ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–∫ –µ—Å—Ç—å")
                    # Fallback: –ø–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–∫ –æ–±—ã—á–Ω–æ
                    success, all_data = await self.parse_service_url(url)
                else:
                    # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é —É—Å–ª—É–≥—É –æ—Ç–¥–µ–ª—å–Ω–æ
                    for service_url in direct_urls:
                        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ª—É–≥–∏: {service_url}")
                        service_success, service_data = await self.parse_service_url(service_url)
                        if service_success:
                            all_data.extend(service_data)
                            success = True
                        
                        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                        await asyncio.sleep(2)
            else:
                # –û–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏
                success, all_data = await self.parse_service_url(url)
            
            if success:
                self.last_parsed_urls[url] = datetime.now()
                logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ URL: {url} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ, –ø–æ–ª—É—á–µ–Ω–æ {len(all_data)} –∑–∞–ø–∏—Å–µ–π")
            else:
                logger.error(f"–ü–∞—Ä—Å–∏–Ω–≥ URL: {url} –∑–∞–≤–µ—Ä—à–µ–Ω –Ω–µ—É–¥–∞—á–Ω–æ")
            
            return success, all_data
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ URL {url}: {str(e)}")
            return False, []

    async def parse_service_url(self, url: str) -> Tuple[bool, List[Dict[str, Any]]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä—è–º–æ–≥–æ URL —É—Å–ª—É–≥–∏.
        –û–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è 4-—à–∞–≥–æ–≤–æ–≥–æ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ YClients.
        
        Args:
            url: URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
            
        Returns:
            Tuple[bool, List[Dict[str, Any]]]: –°—Ç–∞—Ç—É—Å —É—Å–ø–µ—Ö–∞ –∏ —Å–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        """
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏ —É—Å–ª—É–≥–∏: {url}")
        all_data = []
        
        try:
            # –ù–∞–≤–∏–≥–∞—Ü–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
            navigation_success = await self.navigate_to_url(url)
            if not navigation_success:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
                return False, []
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω—Ç–∏–±–æ—Ç-–∑–∞—â–∏—Ç—É
            if not await self.check_for_antibot():
                logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∑–∞—â–∏—Ç–∞ –æ—Ç –±–æ—Ç–æ–≤, —Å–º–µ–Ω–∞ –ø—Ä–æ–∫—Å–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫")
                return False, []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ YClients URL
            if self.is_yclients_url(url):
                logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º 4-—à–∞–≥–æ–≤—É—é –Ω–∞–≤–∏–≥–∞—Ü–∏—é YClients")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é 4-—à–∞–≥–æ–≤—É—é –Ω–∞–≤–∏–≥–∞—Ü–∏—é
                all_data = await self.navigate_yclients_flow(self.page, url)
            else:
                logger.info("üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤)
                available_dates = await self.extract_available_dates()
                if not available_dates:
                    logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç—ã")
                    return False, []
                    
                # –î–ª—è –∫–∞–∂–¥–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π –¥–∞—Ç—ã –∏–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ª–æ—Ç—ã
                for date_info in available_dates:
                    date = date_info["date"]
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤
                    time_slots = await self.extract_time_slots(date)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                    all_data.extend(time_slots)
                    
                    # –ò–º–∏—Ç–∞—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: —Å–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    await asyncio.sleep(self.browser_manager.get_random_delay(1, 3))
            
            success = len(all_data) > 0
            if success:
                self.last_parsed_urls[url] = datetime.now()
                logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ URL: {url} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ, –ø–æ–ª—É—á–µ–Ω–æ {len(all_data)} –∑–∞–ø–∏—Å–µ–π")
            else:
                logger.warning(f"–ü–∞—Ä—Å–∏–Ω–≥ URL: {url} –∑–∞–≤–µ—Ä—à–µ–Ω, –Ω–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã")
                
            return success, all_data
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏ {url}: {str(e)}")
            return False, []
    
    def is_yclients_url(self, url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π YClients."""
        yclients_indicators = [
            'yclients.com',
            'record-type',
            'personal/',
            'select-time',
            'select-master'
        ]
        return any(indicator in url for indicator in yclients_indicators)

    async def parse_all_urls(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å–æ –≤—Å–µ—Ö URL.
        
        Returns:
            Dict[str, List[Dict[str, Any]]]: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL
        """
        logger.info("–ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ—Ö URL")
        results = {}
        
        try:
            await self.initialize()
            
            for url in self.urls:
                retry_count = 0
                success = False
                data = []
                
                # –î–µ–ª–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø—Ä–æ–∫—Å–∏
                while not success and retry_count < MAX_RETRIES:
                    success, data = await self.parse_url(url)
                    
                    if not success:
                        retry_count += 1
                        logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {retry_count}/{MAX_RETRIES} –¥–ª—è {url} –Ω–µ —É–¥–∞–ª–∞—Å—å, —Å–º–µ–Ω–∞ –ø—Ä–æ–∫—Å–∏")
                        
                        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –±—Ä–∞—É–∑–µ—Ä
                        await self.close()
                        
                        # –ú–µ–Ω—è–µ–º –ø—Ä–æ–∫—Å–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –±—Ä–∞—É–∑–µ—Ä
                        self.current_proxy = self.proxy_manager.get_next_proxy()
                        self.browser, self.context = await self.browser_manager.initialize_browser(
                            proxy=self.current_proxy
                        )
                    else:
                        # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                        results[url] = data
                
                # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã, –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
                if not success:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å URL {url} –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")
                    results[url] = []
                
            logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö URL –∑–∞–≤–µ—Ä—à–µ–Ω, –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} URL")
        
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ URL: {str(e)}")
        finally:
            await self.close()
        
        return results

    async def run_single_iteration(self) -> None:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ—Ö URL."""
        logger.info("–ù–∞—á–∞–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        start_time = time.time()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ –≤—Å–µ—Ö URL
            results = await self.parse_all_urls()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            for url, data in results.items():
                if data:
                    logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è URL {url}")
                    await self.db_manager.save_booking_data(url, data)
                else:
                    logger.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è URL {url}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")
        
        elapsed_time = time.time() - start_time
        logger.info(f"–ò—Ç–µ—Ä–∞—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")

    async def run_continuous(self) -> None:
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º."""
        logger.info(f"–ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {PARSE_INTERVAL} —Å–µ–∫—É–Ω–¥")
        
        while True:
            try:
                await self.run_single_iteration()
                logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {PARSE_INTERVAL} —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏")
                await asyncio.sleep(PARSE_INTERVAL)
            
            except KeyboardInterrupt:
                logger.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")
                break
            
            except Exception as e:
                logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                await asyncio.sleep(10)


async def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞."""
    from src.database.db_manager import DatabaseManager
    
    # –ü—Ä–∏–º–µ—Ä URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    urls = [
        "https://yclients.com/company/111111/booking",
        "https://yclients.com/company/222222/booking"
    ]
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    db_manager = DatabaseManager()
    await db_manager.initialize()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
    parser = YClientsParser(urls, db_manager)
    
    # –ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
    await parser.run_single_iteration()
    
    # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
    await db_manager.close()


if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    asyncio.run(main())
